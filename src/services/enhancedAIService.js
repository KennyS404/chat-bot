import OpenAI from 'openai';
import { config } from '../config.js';
import { logger } from '../logger.js';

export class EnhancedAIService {
  constructor() {
    // OpenAI para √°udio (Whisper + TTS)
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });

    // DeepSeek para corre√ß√£o de texto (muito mais barato!)
    this.deepseek = new OpenAI({
      apiKey: config.deepseek.apiKey,
      baseURL: 'https://api.deepseek.com/v1'
    });

    // Armazenar contexto de conversa por usu√°rio
    this.conversationContext = new Map();
  }

  async transcribeAudio(audioBuffer) {
    try {
      logger.info('üéß Transcrevendo √°udio com OpenAI Whisper...');
      const file = new File([audioBuffer], 'audio.mp3', { type: 'audio/mp3' });
      
      const transcription = await this.openai.audio.transcriptions.create({
        file: file,
        model: config.openai.whisperModel,
        language: 'pt',
        response_format: 'text',
      });

      logger.info('‚úÖ Transcri√ß√£o conclu√≠da');
      return transcription;
    } catch (error) {
      logger.error('‚ùå Erro na transcri√ß√£o:', error);
      throw error;
    }
  }

  async detectContentType(text) {
    try {
      logger.info('üîç Analisando tipo de conte√∫do...');
      
      const response = await this.deepseek.chat.completions.create({
        model: 'deepseek-chat',
        messages: [
          {
            role: 'system',
            content: `Analise o texto e identifique se cont√©m:
            1. Fragmento de m√∫sica (letra, melodia, ritmo)
            2. Pergunta de conhecimento geral
            3. Apenas conversa normal
            
            Responda apenas com:
            - "MUSIC" se contiver m√∫sica
            - "QUESTION" se for pergunta de conhecimento
            - "CONVERSATION" se for conversa normal`
          },
          {
            role: 'user',
            content: text
          }
        ],
        temperature: 0.1,
        max_tokens: 50,
      });

      const contentType = response.choices[0].message.content.trim();
      logger.info(`‚úÖ Tipo de conte√∫do detectado: ${contentType}`);
      return contentType;
    } catch (error) {
      logger.error('‚ùå Erro na detec√ß√£o de conte√∫do, usando fallback...');
      return 'CONVERSATION'; // Fallback para conversa normal
    }
  }

  async correctGrammarWithCommand(text) {
    try {
      logger.info('‚úèÔ∏è Corrigindo gram√°tica com comando espec√≠fico...');
      
      const response = await this.deepseek.chat.completions.create({
        model: 'deepseek-chat',
        messages: [
          {
            role: 'system',
            content: `Voc√™ √© um corretor gramatical especializado em portugu√™s brasileiro. 
            
            INSTRU√á√ïES ESPEC√çFICAS:
            - Corrija e melhore o texto
            - Use linguagem formal
            - Seja gentil na corre√ß√£o
            - Mantenha o sentido original
            - Preserve a naturalidade da fala
            
            Formato da resposta:
            - Se houver corre√ß√µes: "Voc√™ quis dizer: [texto corrigido]"
            - Se n√£o houver corre√ß√µes: "‚úÖ Seu √°udio est√° correto!"
            
            IMPORTANTE: Use linguagem formal e seja gentil em todas as corre√ß√µes.`
          },
          {
            role: 'user',
            content: text
          }
        ],
        temperature: 0.3,
        max_tokens: 500,
      });

      const correction = response.choices[0].message.content;
      logger.info('‚úÖ Corre√ß√£o com comando espec√≠fico conclu√≠da');
      return correction;
    } catch (error) {
      logger.error('‚ùå Erro DeepSeek, fallback para OpenAI...');
      
      // Fallback para OpenAI se DeepSeek falhar
      const response = await this.openai.chat.completions.create({
        model: config.openai.gptModel,
        messages: [
          {
            role: 'system',
            content: `Voc√™ √© um corretor gramatical especializado em portugu√™s brasileiro. 
            Corrija e melhore o texto usando linguagem formal e sendo gentil.`
          },
          {
            role: 'user',
            content: text
          }
        ],
        temperature: 0.3,
        max_tokens: 500,
      });

      return response.choices[0].message.content;
    }
  }

  async generateInteractiveResponse(text, contentType, userId) {
    try {
      logger.info('üí¨ Gerando resposta interativa...');
      
      // Obter contexto da conversa
      const context = this.conversationContext.get(userId) || [];
      
      let systemPrompt = '';
      
      // Definir prompt baseado no tipo de conte√∫do
      switch (contentType) {
        case 'MUSIC':
          systemPrompt = `Voc√™ √© um assistente musical amig√°vel. 
          Se o usu√°rio mencionar m√∫sica, cante, ou fale sobre m√∫sica:
          - Identifique a m√∫sica se poss√≠vel
          - Comente sobre o g√™nero musical
          - Mantenha um tom alegre e musical
          - Responda no mesmo idioma do usu√°rio
          - Seja natural e conversacional`;
          break;
          
        case 'QUESTION':
          systemPrompt = `Voc√™ √© um assistente de conhecimento geral.
          Se o usu√°rio fizer uma pergunta:
          - Responda de forma educativa e clara
          - Use linguagem acess√≠vel
          - Responda no mesmo idioma do usu√°rio
          - Mantenha um tom amig√°vel e √∫til`;
          break;
          
        default:
          systemPrompt = `Voc√™ √© um assistente conversacional amig√°vel.
          Mantenha uma conversa natural e envolvente:
          - Responda no mesmo idioma do usu√°rio
          - Seja amig√°vel e interessado
          - Fa√ßa perguntas de volta quando apropriado
          - Mantenha o contexto da conversa`;
      }

      const messages = [
        {
          role: 'system',
          content: systemPrompt
        },
        ...context.slice(-4), // Manter apenas as √∫ltimas 4 mensagens para contexto
        {
          role: 'user',
          content: text
        }
      ];

      const response = await this.deepseek.chat.completions.create({
        model: 'deepseek-chat',
        messages: messages,
        temperature: 0.7,
        max_tokens: 300,
      });

      const assistantResponse = response.choices[0].message.content;
      
      // Atualizar contexto da conversa
      context.push(
        { role: 'user', content: text },
        { role: 'assistant', content: assistantResponse }
      );
      
      // Manter apenas as √∫ltimas 10 mensagens para n√£o sobrecarregar
      if (context.length > 10) {
        context.splice(0, context.length - 10);
      }
      
      this.conversationContext.set(userId, context);
      
      logger.info('‚úÖ Resposta interativa gerada');
      return assistantResponse;
    } catch (error) {
      logger.error('‚ùå Erro na resposta interativa, usando fallback...');
      
      // Fallback simples
      const fallbackResponses = {
        'MUSIC': 'Que legal! Voc√™ gosta de m√∫sica? Qual √© seu g√™nero favorito?',
        'QUESTION': 'Interessante pergunta! Posso ajudar com isso.',
        'CONVERSATION': 'Entendo! Continue me contando mais sobre isso.'
      };
      
      return fallbackResponses[contentType] || 'Obrigado por compartilhar isso comigo!';
    }
  }

  async textToSpeech(text) {
    try {
      logger.info('üîä Gerando √°udio com OpenAI TTS...');
      
      const response = await this.openai.audio.speech.create({
        model: config.openai.ttsModel,
        voice: config.openai.ttsVoice,
        input: text,
        speed: 1.0,
        response_format: 'mp3'
      });

      const arrayBuffer = await response.arrayBuffer();
      const audioBuffer = Buffer.from(arrayBuffer);
      
      logger.info('‚úÖ √Åudio gerado');
      return audioBuffer;
    } catch (error) {
      logger.error('‚ùå Erro no TTS:', error);
      throw error;
    }
  }

  async processAudio(audioBuffer, userId) {
    try {
      // 1. Transcrever o √°udio
      const transcription = await this.transcribeAudio(audioBuffer);
      logger.info('üìù Transcri√ß√£o:', transcription);

      // 2. Detectar tipo de conte√∫do
      const contentType = await this.detectContentType(transcription);
      
      // 3. Corrigir gram√°tica com comando espec√≠fico
      const correction = await this.correctGrammarWithCommand(transcription);
      const hasCorrections = !correction.includes('‚úÖ');
      
      // 4. Gerar resposta interativa
      const interactiveResponse = await this.generateInteractiveResponse(transcription, contentType, userId);
      
      // 5. Gerar √°udio (COMENTADO conforme solicitado)
      let audioResponse = null;
      // if (hasCorrections && config.app.enableAudioResponse) {
      //   const correctedText = correction.replace('Voc√™ quis dizer: ', '');
      //   audioResponse = await this.textToSpeech(correctedText);
      // }
      
      return {
        transcription,
        correction,
        hasCorrections,
        contentType,
        interactiveResponse,
        audioResponse, // Sempre null agora
        provider: {
          transcription: 'OpenAI Whisper',
          correction: 'DeepSeek Chat',
          conversation: 'DeepSeek Chat'
        }
      };
    } catch (error) {
      logger.error('‚ùå Erro no processamento aprimorado:', error);
      throw error;
    }
  }

  // M√©todo para limpar contexto de conversa
  clearConversationContext(userId) {
    this.conversationContext.delete(userId);
    logger.info(`üßπ Contexto de conversa limpo para usu√°rio: ${userId}`);
  }

  // M√©todo para estimativa de custos
  getEstimatedCost(textLength) {
    const tokens = Math.ceil(textLength / 4); // Aproxima√ß√£o
    
    return {
      transcription: 0.006, // $0.006/minuto OpenAI Whisper
      correction: tokens * 0.00000027, // $0.27/1M tokens DeepSeek
      conversation: tokens * 0.00000027, // $0.27/1M tokens DeepSeek
      total: 'Muito econ√¥mico com DeepSeek'
    };
  }
} 